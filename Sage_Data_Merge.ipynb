{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sage Data Merge\n",
    "\n",
    "TO DO:\n",
    "    - Fix notes / documentation\n",
    "    - Streamline the \"as_is\" dataframe, only code for df's in need of modification.   \n",
    "    \n",
    "\n",
    "NOTES FOR TEAM:\n",
    "    - Following 'test_user' records are removed: ULoF3MM1nN gSWn9N D5bzYrfd8E ThpMV2Achc\n",
    "    \n",
    "Dataframe Columns Creation:\n",
    "    \n",
    "    bart_v4\n",
    "        - Created columns for baseline, 21-day-assessment, bart250, bart0.25\n",
    "    \n",
    "    behavior_choices_4\n",
    "        - Created columns for baseline (not reenrollment - has duplicates)\n",
    "      \n",
    "    delay_discounting\n",
    "        - Created columns for baseline, 21-day-assessment, dd_time_6_month, dd_money_6_month, dd_money_1_month,           dd_time_1_year    \n",
    "    \n",
    "    discounting_raw\n",
    "        - Created columns for baseline, 21-day-assessment, money, probability.\n",
    "        \n",
    "    evening_notification\n",
    "        - Only included \"baseline\" data.  Did not include \"reenrollment\" or \"set_evening_survey\" because of               duplicates.\n",
    "        \n",
    "    gonogo\n",
    "        - NEED TO RECTIFY DUPLICATES (see below for details)\n",
    "        \n",
    "    morning_notification\n",
    "        - created columns for baseline only.\n",
    "    \n",
    "    PAM multiple\n",
    "        - created columns for baseline and 21-day-assessment.\n",
    "        \n",
    "    - Missing Dataframes\n",
    "        PAM_v2 (ONLY INCLUDES AM_SURVEY AND PM_SURVEY)\n",
    "        Morning Behavior (ONLY INCLUDES AM_SURVEY)\n",
    "        Morning Yesterday Sem Diff (ONLY INCLUDES AM_SURVEY)\n",
    "        Morning Yesterday Likert (ONLY INCLUDES AM_SURVEY)\n",
    "        Morning Semantics (ONLY INCLUDES AM_SURVEY)\n",
    "        Comments_v2 - Has duplicates\n",
    "      \n",
    "    - Unexplained duplicates (file, id's):\n",
    "        - digital-marshmallow-as_a_child_likert_bl-v2_8.8.17.csv    ThpMV2Achc\n",
    "        - digital-marshmallow-behavior_choices_1_bl-v1_8.8.17.csv   ThpMV2Achc\n",
    "        - digital-marshmallow-demographics-v2_8.8.17.csv\t\t    ThpMV2Achc\n",
    "        - digital-marshmallow-behavior_likert_bl-v2_8.8.17.csv\t\tThpMV2Achc\n",
    "        - digital-marshmallow-generally_sem_diff_bl-v2_8.8.17.csv\tThpMV2Achc\n",
    "        - digital-marshmallow-past_year_likert_bl-v3_8.8.17.csv\t\tThpMV2Achc\n",
    "        - digital-marshmallow-comments-v2_8.8.17.csv \t\t\t    CdtW9X Db8hWK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, pandas as pd, numpy as np, re\n",
    "from functools import reduce\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "#NOTE TO SELF: redo the relative paths.\n",
    "sage = '/home/wraikes/Dropbox/partnership/DMTBilly data - Copy/Sage Data'\n",
    "os.chdir(sage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_dupes(df):\n",
    "    #'Must confirm removal of these dupes, especially ThpMV2Achc\n",
    "    test_users = ['ULoF3MM1nN', 'gSWn9N', 'D5bzYrfd8E', 'ThpMV2Achc']\n",
    "    return df[~df.externalId.isin(test_users)]\n",
    "\n",
    "def dupe_check(df):\n",
    "    return len(df.externalId) == len(df.externalId.unique()) and df.externalId > 0\n",
    "\n",
    "def new_cols(df, append):\n",
    "    # Remove: 'metadata.json.' and 'data.json.'.\n",
    "    col_re = re.compile('metadata.json.|data.json.')\n",
    "    df.columns = list(map(lambda x: re.sub(col_re, '', x), df.columns))\n",
    "    \n",
    "    # Append df identifier to columns.\n",
    "    df.columns = list(map(lambda x: x + append, df.columns))\n",
    "    df = df.rename(columns = {'externalId' + append: 'externalId'})\n",
    "\n",
    "    return df\n",
    "\n",
    "def create_new_df(df, func, attributes):\n",
    "    dfs = []\n",
    "    \n",
    "    for att in attributes:\n",
    "        if len(att) == 3:\n",
    "            new_df = func(df, att[1], att[2])\n",
    "        else:\n",
    "            new_df = func(df, att[1])\n",
    "        new_df = new_cols(new_df, att[0])\n",
    "        dfs.append(new_df)\n",
    "\n",
    "    df_merge = reduce(lambda left, right: pd.merge(left, right, how = 'outer',\n",
    "                                                   on='externalId'), \n",
    "                                                   dfs)\n",
    "    \n",
    "    return df_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_users = ['ULoF3MM1nN', 'gSWn9N', 'D5bzYrfd8E', 'ThpMV2Achc']\n",
    "files_to_exclude = ['digital-marshmallow-status_8.8.17.csv',\n",
    "                    'digital-marshmallow-appVersion_8.8.17.csv']\n",
    "\n",
    "files_as_is = []\n",
    "\n",
    "for file in os.listdir():\n",
    "    if file not in files_to_exclude:\n",
    "        df = pd.read_csv(file)\n",
    "        df = remove_dupes(df)\n",
    "        if dupe_check(df):\n",
    "            files_as_is.append(file)\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names_as_is = ['_-_past_year_likert_21', \n",
    "               '_-_behavior_choices_1',\n",
    "               '_-_comments_21',\n",
    "               '_-_demos',\n",
    "               '_-_behavior_lk_21',\n",
    "               '_-_behavior_lk_bl',\n",
    "               '_-_generally_sem_bl',\n",
    "               '_-_generally_sem_21',\n",
    "               '_-_as_a_child',\n",
    "               '_-_past_year_likert_bl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_dfs = {}\n",
    "\n",
    "for file, name in zip(files_as_is, names_as_is):\n",
    "    df = pd.read_csv(file)\n",
    "    df = remove_dupes(df)\n",
    "    df = new_cols(df, name)\n",
    "    new_dfs[name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all([dupe_check(df) for name, df in new_dfs.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame: Bart_V4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_v4 = pd.read_csv('digital-marshmallow-bart-v4_8.8.17.csv')\n",
    "bart_v4 = remove_dupes(bart_v4)\n",
    "\n",
    "dupe_check(bart_v4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bart_dataframe(df, var, survey):\n",
    "    cols = df.columns\n",
    "    new_df = pd.DataFrame(columns = cols)\n",
    "    \n",
    "    for ix, row in df.iterrows():\n",
    "        if row['data.json.variable_label'] == var and row['metadata.json.taskIdentifier'] == survey:\n",
    "            new_df = new_df.append(row, ignore_index=True)\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bart_attributes = [\n",
    "    ['_-_bart_v4_bl_0.25', 'BART0.25', 'baseline'],\n",
    "    ['_-_bart_v4_bl_250', 'BART250.00', 'baseline'],\n",
    "    ['_-_bart_v4_21_0.25', 'BART250.00', '21-day-assessment'],\n",
    "    ['_-_bart_v4_21_250', 'BART250.00', '21-day-assessment']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_v4 = create_new_df(bart_v4, bart_dataframe, bart_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_v4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupe_check(bart_v4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame: Behavior_choices_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_4 = pd.read_csv('digital-marshmallow-behavior_choices_4_bl-v2_8.8.17.csv')\n",
    "behavior_4 = remove_dupes(behavior_4)\n",
    "\n",
    "dupe_check(behavior_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def behave_dataframe(df, survey):\n",
    "    cols = df.columns\n",
    "    new_df = pd.DataFrame(columns = cols)\n",
    "    \n",
    "    for ix, row in df.iterrows():\n",
    "        if row['metadata.json.taskIdentifier'] == survey:\n",
    "            new_df = new_df.append(row, ignore_index=True)\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "behavior_4_attributes = [\n",
    "    ['_-_behavior_4_bl', 'baseline'],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_4 = create_new_df(behavior_4, behave_dataframe, behavior_4_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupe_check(behavior_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame: Delay Discounting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay = pd.read_csv('digital-marshmallow-delay_discounting_raw-v6_8.8.17.csv')\n",
    "delay = remove_dupes(delay)\n",
    "\n",
    "dupe_check(delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def delay_dataframe(df, var, survey):\n",
    "    cols = df.columns\n",
    "    new_df = pd.DataFrame(columns = cols)\n",
    "    \n",
    "    for ix, row in df.iterrows():\n",
    "        if row['data.json.variableLabel'] == var and row['metadata.json.taskIdentifier'] == survey:\n",
    "            new_df = new_df.append(row, ignore_index=True)\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bl = 'baseline'\n",
    "_21 = '21-day-assessment'\n",
    "\n",
    "delay_attributes = [['dd_time_6_month', bl, '_-_delay_bl_time_6_month'],\n",
    "                    ['dd_money_6_month', bl, '_-_delay_bl_money_6_month'],\n",
    "                    ['dd_money_1_month', bl, '_-_delay_bl_money_1_month'],\n",
    "                    ['dd_time_1_year', bl, '_-_delay_bl_time_1_year'],\n",
    "                    ['dd_time_6_month', _21, '_-_delay_21_time_6_month'],\n",
    "                    ['dd_money_6_month', _21, '_-_delay_21_money_6_month'],\n",
    "                    ['dd_money_1_month', _21, '_-_delay_21_money_1_month'],\n",
    "                    ['dd_time_1_year', _21, '_-_delay_21_time_1_year']]\n",
    "\n",
    "delay = create_new_df(df=delay, func=delay_dataframe, attributes=delay_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupe_check(delay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame: Discounting Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discount = pd.read_csv('digital-marshmallow-discounting_raw-v2_8.8.17.csv')\n",
    "discount = remove_dupes(discount)\n",
    "\n",
    "dupe_check(discount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discount_dataframe(df, var, survey):\n",
    "    cols = df.columns\n",
    "    new_df = pd.DataFrame(columns = cols)\n",
    "    \n",
    "    for ix, row in df.iterrows():\n",
    "        if row['data.json.variableLabel'] == var and row['metadata.json.taskIdentifier'] == survey:\n",
    "            new_df = new_df.append(row, ignore_index=True)\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bl = 'baseline'\n",
    "_21 = '21-day-assessment'\n",
    "\n",
    "discount_attributes = [['pd_constant_money', bl, '_-_discount_bl_money'],\n",
    "                       ['pd_constant_probabiliy', bl, '_-_discount_bl_prob'],\n",
    "                       ['pd_constant_money', _21, '_-_discount_21_money'],\n",
    "                       ['pd_constant_probability', _21, '_-_discount_21_prob']]\n",
    "\n",
    "discount = create_new_df(df=discount, func=discount_dataframe, attributes=discount_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupe_check(discount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame: Evening Notification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evening_note = pd.read_csv('digital-marshmallow-evening_notification_time-v2_8.8.17.csv')\n",
    "evening_note = remove_dupes(evening_note)\n",
    "\n",
    "dupe_check(evening_note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evening_note_dataframe(df, survey):\n",
    "    cols = df.columns\n",
    "    new_df = pd.DataFrame(columns = cols)\n",
    "    \n",
    "    for ix, row in df.iterrows():\n",
    "        if row['metadata.json.taskIdentifier'] == survey:\n",
    "            new_df = new_df.append(row, ignore_index=True)\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evening_note_attributes = [\n",
    "    ['_-_evening_note_bl', 'baseline']\n",
    "]\n",
    "\n",
    "evening_note_bl = create_new_df(evening_note, evening_note_dataframe, evening_note_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupe_check(evening_note_bl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame: GoNoGo - PLACEHOLDER (Extra Record - ksJM3Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gonogo = pd.read_csv('digital-marshmallow-goNoGo-v2_8.8.17.csv')\n",
    "gonogo = remove_dupes(gonogo)\n",
    "\n",
    "dupe_check(gonogo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gonogo_dataframe(df, var, survey):\n",
    "    cols = df.columns\n",
    "    new_df = pd.DataFrame(columns = cols)\n",
    "    \n",
    "    for ix, row in df.iterrows():\n",
    "        if row['data.json.variable_label'] == var and row['metadata.json.taskIdentifier'] == survey:\n",
    "            new_df = new_df.append(row, ignore_index=True)\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bl = 'baseline'\n",
    "_21 = '21-day-assessment'\n",
    "\n",
    "gonogo_attributes = [\n",
    "    ['_-_gonogo_bl_stable', 'go_no_go_stable_stimulus_active_task', bl],\n",
    "    ['_-_gonogo_21_variable', 'go_no_go_variable_stimulus_active_task', bl],\n",
    "    ['_-_gonogo_bl_stable', 'go_no_go_stable_stimulus_active_task', _21],\n",
    "    ['_-_gonogo_21_variable', 'go_no_go_variable_stimulus_active_task', _21]\n",
    "]\n",
    "\n",
    "gonogo = create_new_df(df=gonogo, func=gonogo_dataframe, attributes=gonogo_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupe_check(gonogo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gonogo.externalId[gonogo.externalId.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame: Morning Notifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "morning_note = pd.read_csv('digital-marshmallow-morning_notification_time-v3_8.8.17.csv')\n",
    "morning_note = remove_dupes(morning_note)\n",
    "\n",
    "dupe_check(morning_note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def morning_note_dataframe(df, survey):\n",
    "    cols = df.columns\n",
    "    new_df = pd.DataFrame(columns = cols)\n",
    "    \n",
    "    for ix, row in df.iterrows():\n",
    "        if row['metadata.json.taskIdentifier'] == survey:\n",
    "            new_df = new_df.append(row, ignore_index=True)\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "morning_note_bl = morning_note_dataframe(morning_note, 'baseline', '_-_morning_note_bl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dupe_check(morning_behave_bl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame: PAM Multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pam_mult = pd.read_csv('digital-marshmallow-pam_multiple-v2_8.8.17.csv')\n",
    "pam_mult = remove_dupes(pam_mult)\n",
    "\n",
    "dupe_check(pam_mult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pam_mult_dataframe(df, survey):\n",
    "    cols = df.columns\n",
    "    new_df = pd.DataFrame(columns = cols)\n",
    "    \n",
    "    for ix, row in df.iterrows():\n",
    "        if row['metadata.json.taskIdentifier'] == survey:\n",
    "            new_df = new_df.append(row, ignore_index=True)\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pam_mult_attributes = [\n",
    "    ['_-_pam_mult_bl', 'baseline'],\n",
    "    ['_-_pam_mult_21', '21-day-assessment']\n",
    "]\n",
    "\n",
    "pam_mult = create_new_df(pam_mult, pam_mult_dataframe, pam_mult_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupe_check(pam_mult)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
