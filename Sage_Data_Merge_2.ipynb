{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sage Data Merge\n",
    "\n",
    "TO DO:\n",
    "    - Fix notes / documentation\n",
    "    - Streamline the \"as_is\" dataframe, only code for df's in need of modification.   \n",
    "    \n",
    "\n",
    "NOTES FOR TEAM:\n",
    "    - Following 'test_user' records are removed: ULoF3MM1nN gSWn9N D5bzYrfd8E ThpMV2Achc\n",
    "    \n",
    "Dataframe Columns Creation:\n",
    "    \n",
    "    bart_v4\n",
    "        - Created columns for baseline, 21-day-assessment, bart250, bart0.25\n",
    "    \n",
    "    behavior_choices_4\n",
    "        - Created columns for baseline, reenrollment\n",
    "    \n",
    "    comment_v2 -- DID NOT CLEAN YET!!!\n",
    "        - CdtW9X Db8hWK duplicate records\n",
    "    \n",
    "    delay_discounting\n",
    "        - Created columns for baseline, 21-day-assessment, dd_time_6_month, dd_money_6_month, dd_money_1_month,           dd_time_1_year    \n",
    "    \n",
    "    discounting_raw\n",
    "        Created columns for baseline, 21-day-assessment, money, probability.\n",
    "        \n",
    "    evening_notification\n",
    "        - Only included \"baseline\" data.  Did not include \"reenrollment\" or \"set_evening_survey\" because of               duplicates.\n",
    "        \n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    - Unexplained duplicates (file, id's):\n",
    "        - digital-marshmallow-as_a_child_likert_bl-v2_8.8.17.csv    ThpMV2Achc\n",
    "        - digital-marshmallow-behavior_choices_1_bl-v1_8.8.17.csv   ThpMV2Achc\n",
    "        - digital-marshmallow-demographics-v2_8.8.17.csv\t\t    ThpMV2Achc\n",
    "        - digital-marshmallow-behavior_likert_bl-v2_8.8.17.csv\t\tThpMV2Achc\n",
    "        - digital-marshmallow-generally_sem_diff_bl-v2_8.8.17.csv\tThpMV2Achc\n",
    "        - digital-marshmallow-past_year_likert_bl-v3_8.8.17.csv\t\tThpMV2Achc\n",
    "        - digital-marshmallow-comments-v2_8.8.17.csv \t\t\t    CdtW9X Db8hWK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, pandas as pd, numpy as np, re\n",
    "from functools import reduce\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "#NOTE TO SELF: redo the relative paths.\n",
    "sage = '/home/wraikes/Dropbox/partnership/DMTBilly data - Copy/Sage Data'\n",
    "os.chdir(sage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_dupes(df):\n",
    "    #'Must confirm removal of these dupes, especially ThpMV2Achc\n",
    "    test_users = ['ULoF3MM1nN', 'gSWn9N', 'D5bzYrfd8E', 'ThpMV2Achc']\n",
    "    return df[~df.externalId.isin(test_users)]\n",
    "\n",
    "def dupe_check(df):\n",
    "    return len(df.externalId) == len(df.externalId.unique())\n",
    "\n",
    "def new_cols(df, append):\n",
    "    # Remove: 'metadata.json.' and 'data.json.'.\n",
    "    col_re = re.compile('metadata.json.|data.json.')\n",
    "    df.columns = list(map(lambda x: re.sub(col_re, '', x), df.columns))\n",
    "    \n",
    "    # Append df identifier to columns.\n",
    "    df.columns = list(map(lambda x: x + append, df.columns))\n",
    "    df = df.rename(columns = {'externalId' + append: 'externalId'})\n",
    "\n",
    "    return df\n",
    "\n",
    "def create_new_df(df, func, attributes):\n",
    "    dfs = []\n",
    "    \n",
    "    for att in attributes:\n",
    "        new_df = func(df, att[0], att[1])\n",
    "        new_df = new_cols(new_df, att[2])\n",
    "        dfs.append(new_df)\n",
    "\n",
    "    df_merge = reduce(lambda left, right: pd.merge(left, right, how = 'outer',\n",
    "                                                   on='externalId'), \n",
    "                                                   dfs)\n",
    "    \n",
    "    return df_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_users = ['ULoF3MM1nN', 'gSWn9N', 'D5bzYrfd8E', 'ThpMV2Achc']\n",
    "files_to_exclude = ['digital-marshmallow-status_8.8.17.csv',\n",
    "                    'digital-marshmallow-appVersion_8.8.17.csv']\n",
    "\n",
    "files_as_is = []\n",
    "files_to_modify = []\n",
    "\n",
    "for file in os.listdir():\n",
    "    if file not in files_to_exclude:\n",
    "        df = pd.read_csv(file)\n",
    "        df = remove_dupes(df)\n",
    "        if dupe_check(df):\n",
    "            files_as_is.append(file)\n",
    "        else:\n",
    "            files_to_modify.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names_as_is = ['_-_past_year_likert_21', \n",
    "               '_-_behavior_choices_1',\n",
    "               '_-_comments_21',\n",
    "               '_-_demos',\n",
    "               '_-_behavior_lk_21',\n",
    "               '_-_behavior_lk_bl',\n",
    "               '_-_generally_sem_bl',\n",
    "               '_-_generally_sem_21',\n",
    "               '_-_as_a_child',\n",
    "               '_-_past_year_likert_bl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dfs = {}\n",
    "\n",
    "for file, name in zip(files_as_is, names_as_is):\n",
    "    df = pd.read_csv(file)\n",
    "    df = remove_dupes(df)\n",
    "    df = new_cols(df, name)\n",
    "    new_dfs[name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all([dupe_check(df) for name, df in new_dfs.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame: As_a_child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "as_a_child1 = pd.read_csv('digital-marshmallow-as_a_child_likert_bl-v2_8.8.17.csv')\n",
    "as_a_child1 = remove_dupes(as_a_child)\n",
    "\n",
    "dupe_check(as_a_child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "as_a_child = new_cols(as_a_child, '_-_as_a_child')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame: Bart_V4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_v4 = pd.read_csv('digital-marshmallow-bart-v4_8.8.17.csv')\n",
    "bart_v4 = remove_dupes(bart_v4)\n",
    "\n",
    "dupe_check(bart_v4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bart_dataframe(df, bart, survey):\n",
    "    cols = df.columns\n",
    "    new_df = pd.DataFrame(columns = cols)\n",
    "    \n",
    "    for ix, row in df.iterrows():\n",
    "        if row['data.json.variable_label'] == bart and row['metadata.json.taskIdentifier'] == survey:\n",
    "            new_df = new_df.append(row, ignore_index=True)\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_bl_0 = bart_dataframe(bart_v4, 'BART0.25', 'baseline')\n",
    "bart_bl_0 = new_cols(bart_bl_0, '_-_bart_v4_bl_0.25')\n",
    "\n",
    "bart_bl_250 = bart_dataframe(bart_v4, 'BART250.00', 'baseline')\n",
    "bart_bl_250 = new_cols(bart_bl_250, '_-_bart_v4_bl_250')\n",
    "\n",
    "bart_21_0 = bart_dataframe(bart_v4, 'BART250.00', '21-day-assessment')\n",
    "bart_21_0 = new_cols(bart_21_0, '_-_bart_v4_21_0.25')\n",
    "\n",
    "bart_21_250 = bart_dataframe(bart_v4, 'BART250.00', '21-day-assessment')\n",
    "bart_21_250 = new_cols(bart_21_250, '_-_bart_v4_21_250')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfs = [bart_bl_0, bart_bl_250, bart_21_0, bart_21_250]\n",
    "bart_v4 = reduce(lambda left, right: pd.merge(left, right, how = 'outer',\n",
    "                                              on='externalId'), \n",
    "                                              dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupe_check(bart_v4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame: Behavior_choices_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_1 = pd.read_csv('digital-marshmallow-behavior_choices_1_bl-v1_8.8.17.csv')\n",
    "behavior_1 = remove_dupes(behavior_1)\n",
    "\n",
    "dupe_check(behavior_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "behavior_1 = new_cols(behavior_1, '_-_behavior_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame: Behavior_choices_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_4 = pd.read_csv('digital-marshmallow-behavior_choices_4_bl-v2_8.8.17.csv')\n",
    "behavior_4 = remove_dupes(behavior_4)\n",
    "\n",
    "dupe_check(behavior_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def behave_dataframe(df, survey):\n",
    "    cols = df.columns\n",
    "    new_df = pd.DataFrame(columns = cols)\n",
    "    \n",
    "    for ix, row in df.iterrows():\n",
    "        if row['metadata.json.taskIdentifier'] == survey:\n",
    "            new_df = new_df.append(row, ignore_index=True)\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove all \"reenrollment cases\"\n",
    "behavior_4_bl = behave_dataframe(behavior_4, 'baseline')\n",
    "behavior_4_bl = new_cols(behavior_4_bl, '_-_behavior_4_bl')\n",
    "\n",
    "behavior_4_re = behave_dataframe(behavior_4, 'reenrollment')\n",
    "behavior_4_re = behave_dataframe(behavior_4, '_-_behavior_4_re')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfs = [behavior_4_re, behavior_4_bl]\n",
    "behavior_4 = reduce(lambda left, right: pd.merge(left, right, how = 'outer',\n",
    "                                                 on='externalId'), \n",
    "                                                 dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupe_check(behavior_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame: Behavior_likert_21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_lk_21 = pd.read_csv('digital-marshmallow-behavior_likert_21-v2_8.8.17.csv')\n",
    "behavior_lk_21 = remove_dupes(behavior_lk_21)\n",
    "\n",
    "len(behavior_lk_21.externalId) == len(behavior_lk_21.externalId.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "behavior_lk_21 = new_cols(behavior_lk_21, '_-_behavior_lk_21')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame: Behavior_likert_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "behavior_lk_bl = pd.read_csv('digital-marshmallow-behavior_likert_bl-v2_8.8.17.csv')\n",
    "behavior_lk_bl = remove_dupes(behavior_lk_bl)\n",
    "\n",
    "dupe_check(behavior_lk_bl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "behavior_lk_bl = new_cols(behavior_lk_bl, '_-_behavior_lk_bl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame: Comments 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_21 = pd.read_csv('digital-marshmallow-comments_21-v2_8.8.17.csv')\n",
    "comments_21 = remove_dupes(comments_21)\n",
    "\n",
    "dupe_check(comments_21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comments_21 = new_cols(comments_21, '_-_comments_21')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame: Comments v2 - PLACEHOLDER (INCLUDES EXTRA DUPES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_v2 = pd.read_csv('digital-marshmallow-comments-v2_8.8.17.csv')\n",
    "comments_v2 = remove_dupes(comments_v2)\n",
    "\n",
    "dupe_check(comments_v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame: Delay Discounting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay = pd.read_csv('digital-marshmallow-delay_discounting_raw-v6_8.8.17.csv')\n",
    "delay = remove_dupes(delay)\n",
    "\n",
    "dupe_check(delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def delay_dataframe(df, var, survey):\n",
    "    cols = df.columns\n",
    "    new_df = pd.DataFrame(columns = cols)\n",
    "    \n",
    "    for ix, row in df.iterrows():\n",
    "        if row['data.json.variableLabel'] == var and row['metadata.json.taskIdentifier'] == survey:\n",
    "            new_df = new_df.append(row, ignore_index=True)\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bl = 'baseline'\n",
    "_21 = '21-day-assessment'\n",
    "\n",
    "delay_attributes = [['dd_time_6_month', bl, '_-_delay_bl_time_6_month'],\n",
    "                    ['dd_money_6_month', bl, '_-_delay_bl_money_6_month'],\n",
    "                    ['dd_money_1_month', bl, '_-_delay_bl_money_1_month'],\n",
    "                    ['dd_time_1_year', bl, '_-_delay_bl_time_1_year'],\n",
    "                    ['dd_time_6_month', _21, '_-_delay_21_time_6_month'],\n",
    "                    ['dd_money_6_month', _21, '_-_delay_21_money_6_month'],\n",
    "                    ['dd_money_1_month', _21, '_-_delay_21_money_1_month'],\n",
    "                    ['dd_time_1_year', _21, '_-_delay_21_time_1_year']]\n",
    "\n",
    "delay = create_new_df(df=delay, func=delay_dataframe, attributes=delay_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupe_check(delay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame: Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = pd.read_csv('digital-marshmallow-demographics-v2_8.8.17.csv')\n",
    "demo = remove_dupes(demo)\n",
    "\n",
    "dupe_check(demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "demo = new_cols(comments_21, '_-_demos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame: Discounting Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discount = pd.read_csv('digital-marshmallow-discounting_raw-v2_8.8.17.csv')\n",
    "discount = remove_dupes(discount)\n",
    "\n",
    "dupe_check(discount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discount_dataframe(df, var, survey):\n",
    "    cols = df.columns\n",
    "    new_df = pd.DataFrame(columns = cols)\n",
    "    \n",
    "    for ix, row in df.iterrows():\n",
    "        if row['data.json.variableLabel'] == var and row['metadata.json.taskIdentifier'] == survey:\n",
    "            new_df = new_df.append(row, ignore_index=True)\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bl = 'baseline'\n",
    "_21 = '21-day-assessment'\n",
    "\n",
    "discount_attributes = [['pd_constant_money', bl, '_-_discount_bl_money'],\n",
    "                       ['pd_constant_probabiliy', bl, '_-_discount_bl_prob'],\n",
    "                       ['pd_constant_money', _21, '_-_discount_21_money'],\n",
    "                       ['pd_constant_probability', _21, '_-_discount_21_prob']]\n",
    "\n",
    "discount = create_new_df(df=discount, func=discount_dataframe, attributes=discount_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupe_check(discount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame: Evening Notification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evening_note = pd.read_csv('digital-marshmallow-evening_notification_time-v2_8.8.17.csv')\n",
    "evening_note = remove_dupes(evening_note)\n",
    "\n",
    "dupe_check(evening_note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evening_note_dataframe(df, survey, append):\n",
    "    cols = df.columns\n",
    "    new_df = pd.DataFrame(columns = cols)\n",
    "    \n",
    "    for ix, row in df.iterrows():\n",
    "        if row['metadata.json.taskIdentifier'] == survey:\n",
    "            new_df = new_df.append(row, ignore_index=True)\n",
    "    \n",
    "    new_df = new_cols(new_df, append)\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evening_note_bl = evening_note_dataframe(evening_note, 'baseline', '_-_evening_note_bl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupe_check(evening_note_bl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame: Evening Sem - PLACEHOLDER (ONLY INCLUDE PM_SURVEY, NO IDENTIFIERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evening_sem = pd.read_csv('digital-marshmallow-evening_sem_diff-v2_8.8.17.csv')\n",
    "evening_sem = remove_dupes(evening_sem)\n",
    "\n",
    "dupe_check(evening_sem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame: Generally Sem Diff 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generally_21 = pd.read_csv('digital-marshmallow-generally_sem_diff_21-v2_8.8.17.csv')\n",
    "generally_21 = remove_dupes(generally_21)\n",
    "\n",
    "dupe_check(generally_21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generally_21 = new_cols(generally_21, '_-_generally_21')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame: Generally Sem Diff BL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generally_bl = pd.read_csv('digital-marshmallow-generally_sem_diff_bl-v2_8.8.17.csv')\n",
    "generally_bl = remove_dupes(generally_bl)\n",
    "\n",
    "dupe_check(generally_bl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generally_bl = new_cols(generally_bl, '_-_generally_bl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame: GoNoGo - PLACEHOLDER (DUPLICATES: ksJM3Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gonogo = pd.read_csv('digital-marshmallow-goNoGo-v2_8.8.17.csv')\n",
    "gonogo = remove_dupes(gonogo)\n",
    "\n",
    "dupe_check(gonogo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gonogo_dataframe(df, var, survey):\n",
    "    cols = df.columns\n",
    "    new_df = pd.DataFrame(columns = cols)\n",
    "    \n",
    "    for ix, row in df.iterrows():\n",
    "        if row['data.json.variable_label'] == var and row['metadata.json.taskIdentifier'] == survey:\n",
    "            new_df = new_df.append(row, ignore_index=True)\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bl = 'baseline'\n",
    "_21 = '21-day-assessment'\n",
    "\n",
    "gonogo_attributes = [['go_no_go_stable_stimulus_active_task', bl, '_-_gonogo_bl_stable'],\n",
    "                     ['go_no_go_variable_stimulus_active_task', bl, '_-_gonogo_21_variable'],\n",
    "                     ['go_no_go_stable_stimulus_active_task', _21, '_-_gonogo_bl_stable'],\n",
    "                     ['go_no_go_variable_stimulus_active_task', _21, '_-_gonogo_21_variable']]\n",
    "\n",
    "gonogo = create_new_df(df=gonogo, func=gonogo_dataframe, attributes=gonogo_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupe_check(gonogo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gonogo.externalId[gonogo.externalId.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame: Morning Behavior PLACEHOLDER (ONLY INCLUDES AM_SURVEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame: Morning Notifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morning_note = pd.read_csv('digital-marshmallow-morning_notification_time-v3_8.8.17.csv')\n",
    "morning_note = remove_dupes(morning_note)\n",
    "\n",
    "dupe_check(morning_note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def morning_note_dataframe(df, survey, append):\n",
    "    cols = df.columns\n",
    "    new_df = pd.DataFrame(columns = cols)\n",
    "    \n",
    "    for ix, row in df.iterrows():\n",
    "        if row['metadata.json.taskIdentifier'] == survey:\n",
    "            new_df = new_df.append(row, ignore_index=True)\n",
    "    \n",
    "    new_df = new_cols(new_df, append)\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morning_note_bl = morning_note_dataframe(morning_note, 'baseline', '_-_morning_note_bl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupe_check(morning_behave_bl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame: Morning Semantics PLACEHOLDER (ONLY INCLUDES AM_SURVEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame: Morning Yesterday Likert PLACEHOLDER (ONLY INCLUDES AM_SURVEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame: Morning Yesterday Sem Diff PLACEHOLDER (ONLY INCLUDES AM_SURVEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame: PAM Multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pam_mult = pd.read_csv('digital-marshmallow-pam_multiple-v2_8.8.17.csv')\n",
    "pam_mult = remove_dupes(pam_mult)\n",
    "\n",
    "dupe_check(pam_mult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pam_mult_dataframe(df, survey, append):\n",
    "    cols = df.columns\n",
    "    new_df = pd.DataFrame(columns = cols)\n",
    "    \n",
    "    for ix, row in df.iterrows():\n",
    "        if row['metadata.json.taskIdentifier'] == survey:\n",
    "            new_df = new_df.append(row, ignore_index=True)\n",
    "    \n",
    "    new_df = new_cols(new_df, append)\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pam_mult_bl = pam_mult_dataframe(pam_mult, 'baseline', '_-_pam_mult_bl')\n",
    "pam_mult_21 = pam_mult_dataframe(pam_mult, '21-day-assessment', '_-_pam_mult_21')\n",
    "\n",
    "dfs = [pam_mult_bl, pam_mult_21]\n",
    "pam_mult = reduce(lambda left, right: pd.merge(left, right, how = 'outer',\n",
    "                                               on='externalId'), \n",
    "                                               dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupe_check(pam_mult)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame: PAM_v2 PLACEHOLDER (ONLY INCLUDES AM_SURVEY AND PM_SURVEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
